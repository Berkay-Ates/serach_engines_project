{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\atesb\\Desktop\\lessons\\arama_motorlari\\search_engines_project\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setini yükleyin (örnek: emails.csv)\n",
    "df = pd.read_csv('Data/enron4.csv')  # CSV dosyasını oku\n",
    "\n",
    "# Eğitim, doğrulama ve test setlerine ayırma\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    df['text'], df['label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels, test_size=0.5, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distil_bert_embedding(data: list):\n",
    "    print(\"distil-bert-running\")\n",
    "    embedder = SentenceTransformer(\"distilbert-base-nli-mean-tokens\")\n",
    "    res = embedder.encode(data)\n",
    "    res = [i for  i in res] \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distil-bert-running\n",
      "distil-bert-running\n",
      "distil-bert-running\n",
      "distil-bert-running\n",
      "distil-bert-running\n",
      "distil-bert-running\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF vektörleştiricisini oluştur\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # 5000 kelimeye kadar vektörleştirme\n",
    "X_train = distil_bert_embedding(train_texts.tolist())\n",
    "X_val = distil_bert_embedding(val_texts.tolist())\n",
    "X_test = distil_bert_embedding(test_texts.tolist())\n",
    "\n",
    "\n",
    "y_train_label = distil_bert_embedding(train_labels.tolist())\n",
    "y_val_label = distil_bert_embedding(val_labels.tolist())\n",
    "y_test_label = distil_bert_embedding(test_labels.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ANNModel, self).__init__()\n",
    "        \n",
    "        # Gizli katmanlar\n",
    "        self.fc1 = nn.Linear(input_dim, 512)  \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.25)  \n",
    "\n",
    "        self.fc2 = nn.Linear(512, 256) \n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.fc3 = nn.Linear(256, 64)  \n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.25) \n",
    "\n",
    "        self.fc4 = nn.Linear(64, 16) \n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.fc5 = nn.Linear(16, 1)  \n",
    "        self.sigmoid = nn.Sigmoid()  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoded hedefleri düz hale getirin\n",
    "y_train_label = np.argmax(y_train_label, axis=1)\n",
    "y_val_label = np.argmax(y_val_label, axis=1)\n",
    "y_test_label = np.argmax(y_test_label, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atesb\\AppData\\Local\\Temp\\ipykernel_25312\\2285204572.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  X_train = torch.tensor(X_train, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "y_train_label = torch.tensor(y_train_label, dtype=torch.float32)\n",
    "y_val_label = torch.tensor(y_val_label, dtype=torch.float32)\n",
    "y_test_label = torch.tensor(y_test_label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch TensorDataset oluştur\n",
    "train_data = TensorDataset(X_train, y_train_label)\n",
    "val_data = TensorDataset(X_val, y_val_label)\n",
    "test_data = TensorDataset(X_test, y_test_label)\n",
    "\n",
    "# DataLoader ile batch işlemi\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.0000, Train Acc: 0.00%, Val Loss: 0.0000, Val Acc: 0.00%\n",
      "Epoch [2/10], Train Loss: 0.0000, Train Acc: 0.00%, Val Loss: 0.0000, Val Acc: 0.00%\n",
      "Epoch [3/10], Train Loss: 0.0000, Train Acc: 0.00%, Val Loss: 0.0000, Val Acc: 0.00%\n",
      "Epoch [4/10], Train Loss: 0.0000, Train Acc: 0.00%, Val Loss: 0.0000, Val Acc: 0.00%\n",
      "Epoch [5/10], Train Loss: 0.0000, Train Acc: 0.00%, Val Loss: 0.0000, Val Acc: 0.00%\n",
      "Epoch [6/10], Train Loss: 0.0000, Train Acc: 0.00%, Val Loss: 0.0000, Val Acc: 0.00%\n",
      "Epoch [7/10], Train Loss: 0.0000, Train Acc: 0.00%, Val Loss: 0.0000, Val Acc: 0.00%\n",
      "Epoch [8/10], Train Loss: 0.0000, Train Acc: 0.00%, Val Loss: 0.0000, Val Acc: 0.00%\n",
      "Epoch [9/10], Train Loss: 0.0000, Train Acc: 0.00%, Val Loss: 0.0000, Val Acc: 0.00%\n",
      "Epoch [10/10], Train Loss: 0.0000, Train Acc: 0.00%, Val Loss: 0.0000, Val Acc: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Cihazı belirle (GPU var mı kontrol et)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Modeli oluştur ve GPU'ya taşı\n",
    "model = ANNModel(input_dim=X_train.shape[1]).to(device)\n",
    "\n",
    "# Loss ve optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Binary Cross-Entropy loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Eğitim fonksiyonu\n",
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            # Verileri GPU'ya taşı\n",
    "            inputs, labels = inputs.to(device).float(), labels.to(device).float()\n",
    "            \n",
    "            if labels.dim() == 0:  # Eğer boyutsuzsa\n",
    "                labels = labels.unsqueeze(0)\n",
    "            labels = labels.view(-1)  # Etiketlerin boyutunu düzleştir\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)  # Loss hesapla\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "        train_accuracy = correct_preds / total_preds\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct_preds = 0\n",
    "        val_total_preds = 0\n",
    "        val_running_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                # Verileri GPU'ya taşı\n",
    "                inputs, labels = inputs.to(device).float(), labels.to(device).float()\n",
    "                labels = labels.view(-1)  # Etiketlerin boyutunu düzleştir\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item()\n",
    "\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                val_correct_preds += (predicted == labels).sum().item()\n",
    "                val_total_preds += labels.size(0)\n",
    "\n",
    "        val_accuracy = val_correct_preds / val_total_preds\n",
    "        val_avg_loss = val_running_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], \"\n",
    "              f\"Train Loss: {avg_loss:.4f}, Train Acc: {train_accuracy*100:.2f}%, \"\n",
    "              f\"Val Loss: {val_avg_loss:.4f}, Val Acc: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Eğitim başlat\n",
    "train_model(model, train_data, val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.00%\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "        70.0       0.00      0.00      0.00     448.0\n",
      "       445.0       0.00      0.00      0.00     152.0\n",
      "\n",
      "    accuracy                           0.00     600.0\n",
      "   macro avg       0.00      0.00      0.00     600.0\n",
      "weighted avg       0.00      0.00      0.00     600.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\atesb\\Desktop\\lessons\\arama_motorlari\\search_engines_project\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\atesb\\Desktop\\lessons\\arama_motorlari\\search_engines_project\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\atesb\\Desktop\\lessons\\arama_motorlari\\search_engines_project\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\atesb\\Desktop\\lessons\\arama_motorlari\\search_engines_project\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\atesb\\Desktop\\lessons\\arama_motorlari\\search_engines_project\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\atesb\\Desktop\\lessons\\arama_motorlari\\search_engines_project\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Cihazı belirle (GPU var mı kontrol et)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Test fonksiyonu\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  # Modeli değerlendirme moduna al\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    # Modeli GPU'ya taşı\n",
    "    model = model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # Verileri GPU'ya taşı\n",
    "            inputs, labels = inputs.to(device).float(), labels.to(device).float()\n",
    "\n",
    "            # Modelin çıktısını al\n",
    "            outputs = model(inputs).squeeze()\n",
    "\n",
    "            # Tahminler\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "    test_accuracy = correct_preds / total_preds\n",
    "    print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "    # Sınıflandırma raporu\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # Verileri GPU'ya taşı\n",
    "            inputs, labels = inputs.to(device).float(), labels.to(device).float()\n",
    "\n",
    "            # Modelin çıktısını al\n",
    "            outputs = model(inputs).squeeze()\n",
    "\n",
    "            # Tahminleri topla\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    print(\"\\nTest Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Test üzerinde modelin başarısını ölç\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.00%\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "        70.0       0.00      0.00      0.00     448.0\n",
      "       445.0       0.00      0.00      0.00     152.0\n",
      "\n",
      "    accuracy                           0.00     600.0\n",
      "   macro avg       0.00      0.00      0.00     600.0\n",
      "weighted avg       0.00      0.00      0.00     600.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\atesb\\Desktop\\lessons\\arama_motorlari\\search_engines_project\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\atesb\\Desktop\\lessons\\arama_motorlari\\search_engines_project\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\atesb\\Desktop\\lessons\\arama_motorlari\\search_engines_project\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\atesb\\Desktop\\lessons\\arama_motorlari\\search_engines_project\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\atesb\\Desktop\\lessons\\arama_motorlari\\search_engines_project\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\atesb\\Desktop\\lessons\\arama_motorlari\\search_engines_project\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Test üzerinde modelin başarısını ölç\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_weights_larger.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
